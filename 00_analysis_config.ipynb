{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9126952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n",
      "Welcome to JupyROOT 6.24/06\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# import analyzer\n",
    "import importlib\n",
    "from importlib import reload\n",
    "import os, sys, glob, warnings, glob\n",
    "import scipy\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import joblib\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "import copy as cp\n",
    "\n",
    "# ROOT\n",
    "import ROOT as root\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import collections, colors, transforms\n",
    "\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# %matplotlib widget\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# All other scripits\n",
    "import include_modules_root as rt\n",
    "# Figure configuration are saved in this file include_figure_preset.py\n",
    "from include_figure_preset import * \n",
    "# Set Figure font family, fontsize, ticks, etc.\n",
    "plt_config(family=\"san-serif\", fontsize_multi=1) # or \"serif\", or an exact font name\n",
    "\n",
    "\n",
    "# Redefine a function to save figures with common settings \n",
    "fig_prefix = \"plots/\"    # It's good to keep figures in a separate folder. Can also be set to None.\n",
    "fig_format = \"jpg\"      # for multiple formats, e.g.: \"pdf,png\"\n",
    "SAVE_FIG = False         # Use this flag to turn the figure saving on or off, so that you don't need to modify all notebook to save figure.\n",
    "# You can then do `savefig(filename_without_extension)` to save your plots with these settings\n",
    "savefig = Save_fig(fig_prefix=fig_prefix, exts=fig_format, SAVE= SAVE_FIG, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60830d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure configuration are saved in this file include_figure_preset.py\n",
    "from include_figure_preset import * \n",
    "# Set Figure font family, fontsize, ticks, etc.\n",
    "plt_config(family=\"san-serif\", fontsize_multi=1) # or \"serif\", or an exact font name\n",
    "\n",
    "\n",
    "# Redefine a function to save figures with common settings \n",
    "fig_prefix = \"plots/\"    # It's good to keep figures in a separate folder. Can also be set to None.\n",
    "fig_format = \"jpg\"      # for multiple formats, e.g.: \"pdf,png\"\n",
    "SAVE_FIG = False         # Use this flag to turn the figure saving on or off, so that you don't need to modify all notebook to save figure.\n",
    "# You can then do `savefig(filename_without_extension)` to save your plots with these settings\n",
    "savefig = Save_fig(fig_prefix=fig_prefix, exts=fig_format, SAVE= SAVE_FIG, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a1d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR    = \"/project/def-mdiamond/tomren/mathusla/data/fit_study_6layer\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cb20f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Universal names, Input file, output filenames, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Get a list of filenames to process ---\n",
    "energy_list = [0.1, 0.2, 0.5, 1, 3, 10, 30, 100]\n",
    "name_list = [\"muon\", \"pion\", \"electron\"]\n",
    "name_list_latex = [\"$\\mu^-$\", \"$\\pi^+$\", \"$e^-$\"]\n",
    "pdgid_list = [13, 211, 11]\n",
    "\n",
    "INDS_PAR = [2,0,3,6,4,5] # from CMS coord to DET coord. \n",
    "PAR_LABELS=[\"$x_0$ [cm]\",\"$y_0$ [cm]\", \"$t_0$ [ns]\", \"$v_x$ [cm/ns]\", \"$v_y$ [cm/ns]\", \"$v_z$ [cm/ns]\"]\n",
    "PAR_LABELS_CMS=[\"$x_0$ [cm]\",\"$y_0$ [cm]\",\"$z_0$ [cm]\", \"$t_0$ [ns]\", \"$v_x$ [cm/ns]\", \"$v_y$ [cm/ns]\", \"$v_z$ [cm/ns]\"]\n",
    "PAR_LABELS_RAW=[\"x0\", \"y0\", \"z0\", \"t0\", \"vx\", \"vy\", \"vz\"]\n",
    "PAR_PLOT_RANGES=np.array([[-15,15],[-15,15],[-4,4],[-2,2], [-2,2], [-6,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7bddcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = {}\n",
    "\n",
    "for name in name_list:\n",
    "    file_list_temp = []\n",
    "    for energy in energy_list:\n",
    "        files=glob.glob(f\"{DATA_DIR}/{name}_{energy}_GeV/*/*/stat_seedmod.root\",)\n",
    "        #files=util.Utils.sortByExt(files)\n",
    "        if len(files)>=1:\n",
    "            file_list_temp.append(files[0])\n",
    "        if len(files)>1:\n",
    "            print(f\"More than one file for {name} at {energy} GeV\")\n",
    "    file_list[name] = file_list_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baca4b1",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c081db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_res_pull(data, figs=None, make_legend=False, plot_gauss1=True, label=\"\", figsize=(10,3.5)):\n",
    "    axlabels=[\"$x_0$ [cm]\",\"$y_0$ [cm]\", \"$t_0$ [ns]\", \"$v_x$ [cm/ns]\", \"$v_y$ [cm/ns]\", \"$v_z$ [cm/ns]\"]\n",
    "    ranges=np.array([[-15,15],[-15,15],[-4,4],[-2,2], [-2,2], [-6,6]])\n",
    "\n",
    "    mask_recon_success=data[\"mask_recon_success\"]\n",
    "    recon     =np.array(data[\"recon\"])[mask_recon_success]\n",
    "    recon_unc =np.array(data[\"recon_error\"])[mask_recon_success]\n",
    "    truth     =np.array(data[\"truth\"])[mask_recon_success]\n",
    "\n",
    "    \n",
    "    if figs is None:\n",
    "        figs = []\n",
    "        for i in range(6):\n",
    "            fig,axs=plt.subplots(1,2,figsize=figsize)\n",
    "            figs.append(fig)\n",
    "\n",
    "    for ipar in range(6):\n",
    "        ipar_cms = INDS_PAR[ipar]\n",
    "        residual=(recon-truth)[:,ipar_cms]\n",
    "        pull=util.pull(residual,0,recon_unc[:,ipar_cms])\n",
    "\n",
    "        # plotrange=[-2*np.std(residual_kf), 2*np.std(residual_kf)]\n",
    "        plotrange=ranges[ipar]\n",
    "\n",
    "        # fig,axs=plt.subplots(1,2,figsize=(10,4))\n",
    "        figure(figs[ipar])\n",
    "        axs=figs[ipar].axes\n",
    "        plt.sca(axs[0])\n",
    "        n,ibins,p = hist(residual,range=plotrange,histtype=\"step\",label=label,bins=100);\n",
    "        yscale(\"log\")\n",
    "        ymin, ymax = gca().get_ylim()\n",
    "        ylim(bottom=1, top = max([max(n)*2,ymax]))        \n",
    "        xlabel(\"Reco-truth, \"+axlabels[ipar])\n",
    "        ylabel(\"[counts/bin]\")\n",
    "\n",
    "        plt.sca(axs[1])\n",
    "        n,ibins,p = hist(pull,range=[-5,5],histtype=\"step\",label=label,bins=100);\n",
    "\n",
    "        bincenters=0.5*(ibins[1:]+ibins[:-1])\n",
    "        y = util.Utils.Gauss(bincenters, max(n),0,1)\n",
    "        if plot_gauss1:\n",
    "            plt.plot(bincenters,y,color=\"r\",label=r\"Gauss, $\\sigma$=1\",linestyle=\":\")\n",
    "            \n",
    "        yscale(\"log\")\n",
    "        ymin, ymax = gca().get_ylim()\n",
    "        ylim(bottom=1, top = max([max(n)*2,ymax]))\n",
    "        xlabel(r\"$\\frac{Reco-truth}{Unc_{reco}}$, \"+axlabels[ipar].split(\" \")[0]+\" [$\\sigma$]\")\n",
    "        \n",
    "        if make_legend:\n",
    "            plt.legend(loc=(1.01,0),fontsize=11)\n",
    "    \n",
    "    return figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23404aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_eff(res, PDG_TRUTH = 13):\n",
    "    recon     =np.array(res[\"recon\"])\n",
    "    recon_unc =np.array(res[\"recon_error\"])\n",
    "    truth     =np.array(res[\"truth\"])\n",
    "    \n",
    "    \n",
    "    mask_recon_success=res[\"mask_recon_success\"]\n",
    "    mask_recon_able = (res[\"truth_nlayer\"]>=5)& (res[\"truth_nlayer\"]<=9) # layer 2 is the bottom layer, 9 is the top\n",
    "    \n",
    "    mask_identified= np.zeros(len(res[\"recon\"]),dtype=bool)\n",
    "    for i in range(len(mask_identified)):\n",
    "        n_truth_id = sum(np.array(res[\"par_km_pdgids\"][i])==PDG_TRUTH)\n",
    "        n_false_id = sum(np.array(res[\"par_km_pdgids\"][i])!=PDG_TRUTH)\n",
    "        track_purity = n_truth_id/(n_truth_id+n_false_id)\n",
    "        if n_truth_id>=4 and n_false_id==0:\n",
    "            mask_identified[i]=True\n",
    "    \n",
    "    n_events = len(mask_recon_success)\n",
    "    n_success = np.sum(mask_recon_success)\n",
    "    \n",
    "        \n",
    "    # Make a fixed range cut for tight and looser track\n",
    "    diffx = recon[:,2]-truth[:,2]\n",
    "    diffy = recon[:,0]-truth[:,0]\n",
    "    diffvx = recon[:,6]-truth[:,6]\n",
    "    diffvy = recon[:,4]-truth[:,4] \n",
    "    mask_TIGHT  = (np.abs(diffx)<5) & (np.abs(diffy)<5) & (np.abs(diffvx)<0.5) & (np.abs(diffvy)<0.5)\n",
    "    mask_LOOSER = (np.abs(diffx)<10) & (np.abs(diffy)<10) & (np.abs(diffvx)<1) & (np.abs(diffvy)<1)\n",
    "            \n",
    "            \n",
    "    eff_raw=util.Utils.flatten1d(list(rt.BayesDivide([sum(mask_recon_success)],[len(mask_recon_success)])))\n",
    "    eff_abs_tight=util.Utils.flatten1d(list(rt.BayesDivide([sum(mask_TIGHT&mask_recon_success)],[len(mask_recon_success)])))\n",
    "    eff_abs_loose=util.Utils.flatten1d(list(rt.BayesDivide([sum(mask_LOOSER&mask_recon_success)],[len(mask_recon_success)])))\n",
    "\n",
    "    eff_reconstructible = util.Utils.flatten1d(list(rt.BayesDivide([sum(mask_recon_able)],[len(mask_recon_success)])))\n",
    "    eff_identified=util.Utils.flatten1d(list(rt.BayesDivide([sum(mask_identified&mask_recon_able)],[sum(mask_recon_able)])))\n",
    "    eff_resolution =util.Utils.flatten1d(list(rt.BayesDivide([sum(mask_LOOSER&mask_identified&mask_recon_able)],[sum(mask_identified&mask_recon_able)])))\n",
    "    \n",
    "    if len(eff_resolution)==0:\n",
    "        eff_resolution = [0,0,0]\n",
    "    \n",
    "    return eff_raw, eff_abs_tight, eff_abs_loose, eff_reconstructible,  eff_identified, eff_resolution\n",
    "\n",
    "\n",
    "def calc_resolution(res):\n",
    "    recon     =np.array(res[\"recon\"])\n",
    "    recon_unc =np.array(res[\"recon_error\"])\n",
    "    truth     =np.array(res[\"truth\"])\n",
    "    \n",
    "    \n",
    "    mask_recon_success=res[\"mask_recon_success\"]\n",
    "    ranges=np.array([[-15,15],[-15,15],[-4,4],[-2,2], [-2,2], [-6,6]])\n",
    "    ind = INDS_PAR\n",
    "    \n",
    "    sigmas = []\n",
    "    sigmas_unc = []\n",
    "    fwhms = []\n",
    "    for i in range(6):\n",
    "        diff = recon[:,ind[i]]-truth[:,ind[i]]\n",
    "        n,ibins= np.histogram(diff,bins=100,range=ranges[i]);\n",
    "        \n",
    "        \n",
    "        bincenters=0.5*(ibins[1:]+ibins[:-1])\n",
    "        yerr=np.sqrt(n);yerr[yerr==0]=1\n",
    "        \n",
    "        popt,pcov = rt.fit_tg(bincenters,n,yerr=yerr,function=\"gaus\")\n",
    "        perr = np.sqrt(np.diag(pcov))\n",
    "        \n",
    "        fw = util.Utils.fwhm(bincenters, n)\n",
    "        fwhm = fw[1]-fw[0]\n",
    "        \n",
    "        sigmas.append(popt[2])\n",
    "        sigmas_unc.append(perr[2])\n",
    "        fwhms.append(fwhm)\n",
    "        \n",
    "    return sigmas,sigmas_unc,fwhms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1c02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_km_alltracks(filename, results_fit = None, tree_name=\"integral_tree\", truth_pids = [13,13], nevents=-1):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---\n",
    "    nevents: \n",
    "      -1: all events\n",
    "      (start, stop) from start to stop\n",
    "    \"\"\"\n",
    "    \n",
    "    if results_fit is None:\n",
    "        results_fit={}\n",
    "\n",
    "        \n",
    "    results_fit[\"Entry\"]=[]               # ROOT event entry number\n",
    "    results_fit[\"ndigi\"]=[]               # Total number of digitized hits\n",
    "    results_fit[\"Digi_track_id\"]=[]\n",
    "    results_fit[\"mask_recon_success_track\"]=[]    # Boolean mask \n",
    "    results_fit[\"mask_recon_success_vertex\"]=[]   # Boolean mask \n",
    "    results_fit[\"mask_reconstructible_vertex\"]=[]   # Boolean mask, if an event has two tracks with 4+ hits. The track is required to be from the direct input\n",
    "    results_fit[\"mask_reconstructible2_vertex\"]=[]   # Boolean mask, if an event has two tracks with 4+ hits. The track can be from any particle.  \n",
    "\n",
    "    \n",
    "    results_fit[\"tracks_truth\"]=[]\n",
    "    results_fit[\"tracks_truth_n\"]=[]\n",
    "    results_fit[\"tracks_truth_nlayer\"]=[]\n",
    "    results_fit[\"tracks_truth_pdgids\"]=[]\n",
    "    \n",
    "    results_fit[\"tracks_recon\"]=[]\n",
    "    results_fit[\"tracks_recon_n\"]=[]\n",
    "    results_fit[\"tracks_recon_error\"]=[]          # KF parameter uncertainty. Already taken sqrt()\n",
    "    results_fit[\"tracks_ndigi\"]=[]          #  number of digitized hits in the track\n",
    "    results_fit[\"tracks_ndigi_false\"]=[]    #  number of digitized hits in the track that are not from the truth\n",
    "    results_fit[\"tracks_purity\"]=[]         # List of PDG id of hits in this track \n",
    "    results_fit[\"tracks_pdgids\"]=[]         # List of PDG id of hits in this track \n",
    "    results_fit[\"tracks_chi2\"]=[]           # KF fit chi2\n",
    "    \n",
    "    results_fit[\"vertices_truth\"]=[]\n",
    "    results_fit[\"vertices_ntrack\"]=[]\n",
    "    results_fit[\"vertices_ntrack_truth\"]=[]\n",
    "    results_fit[\"vertices_recon\"]=[]\n",
    "    results_fit[\"vertices_recon_n\"]=[]\n",
    "    results_fit[\"vertices_recon_error\"]=[]\n",
    "    results_fit[\"vertices_recon_cov\"]=[]\n",
    "    results_fit[\"vertices_chi2\"]=[]\n",
    "    \n",
    "\n",
    "\n",
    "    ev = event.Event(filename, 0, tree_name=tree_name)\n",
    "    Tree=ev.Tree\n",
    "    nevents_total = int(ev.Tree.GetEntries())\n",
    "    cut=cutflow.sample_space(\"\")\n",
    "    \n",
    "    if nevents==-1:\n",
    "        nevents = [0, nevents_total]\n",
    "    elif type(nevents) is int:\n",
    "        if nevents_total<nevents:\n",
    "            print(f\"Requested events exceed total {nevents_total}\")\n",
    "        nevents = [0, min(nevents,nevents_total)]\n",
    "    else:\n",
    "        if nevents_total<nevents[1]:\n",
    "            print(f\"Requested events exceed total {nevents_total}\")        \n",
    "        nevents = [nevents[0], min(nevents[1],nevents_total)]\n",
    "\n",
    "    for i_event in tqdm(range(nevents[0], nevents[1])):\n",
    "        ev.EventNumber=i_event\n",
    "        ev.Tree.GetEntry(i_event)\n",
    "        ev.ExtractTruthPhysics_list()\n",
    "        \n",
    "        par_km_ndigi = ev.Tree.Digi_x.size()\n",
    "        \n",
    "        results_fit[\"Entry\"].append(i_event)\n",
    "        results_fit[\"ndigi\"].append(par_km_ndigi)\n",
    "        results_fit[\"Digi_track_id\"].append(util.c2list(ev.Tree.Digi_track_id))\n",
    "        ids=np.array(results_fit[\"Digi_track_id\"][-1])\n",
    "        ys = np.array(util.c2list(ev.Tree.Digi_y))\n",
    "        n_reconstructible=0\n",
    "        n_reconstructible2=0\n",
    "        for g4id in range(0,200):\n",
    "            if len(np.unique(ys[ids==g4id]))>=4:\n",
    "                n_reconstructible+=1\n",
    "        for g4id in np.unique(ids):\n",
    "            if len(np.unique(ys[ids==g4id]))>=4:\n",
    "                n_reconstructible2+=1                \n",
    "        results_fit[\"vertices_ntrack_truth\"].append(n_reconstructible)\n",
    "        if n_reconstructible>=2:\n",
    "            results_fit[\"mask_reconstructible_vertex\"].append(True)\n",
    "        else:\n",
    "            results_fit[\"mask_reconstructible_vertex\"].append(False)   \n",
    "        if n_reconstructible2>=2:\n",
    "            results_fit[\"mask_reconstructible2_vertex\"].append(True)\n",
    "        else:\n",
    "            results_fit[\"mask_reconstructible2_vertex\"].append(False)               \n",
    "\n",
    "        # Get truth (speed need to be calculated by hand)\n",
    "        try:\n",
    "            # Truth position and speed\n",
    "            TruthTracks = []\n",
    "            Truths = []\n",
    "            Truth_nlayer = []\n",
    "            Truth_pdgids = []\n",
    "            for track in ev.truthTrackList_list:\n",
    "                if track[4][0] in truth_pids:\n",
    "                    TruthTracks.append(track)\n",
    "                    dt=track[3][1]-track[3][0]\n",
    "                    vx=(track[0][1]-track[0][0])/dt\n",
    "                    vy=(track[1][1]-track[1][0])/dt\n",
    "                    vz=(track[2][1]-track[2][0])/dt\n",
    "                    truth = [track[0][0], track[1][0], track[2][0], track[3][0],vx,vy,vz]  \n",
    "                    Truths.append(truth)\n",
    "                    Truth_nlayer.append(np.abs(cut.in_layer(track[1][-1])-cut.in_layer(track[1][0])))\n",
    "                    Truth_pdgids.append(track[4][0])\n",
    "            \n",
    "            n_truthtracks=len(TruthTracks)\n",
    "            results_fit[\"tracks_truth\"].append(Truths)  \n",
    "            results_fit[\"tracks_truth_n\"].append(n_truthtracks)  \n",
    "            results_fit[\"tracks_truth_nlayer\"].append(Truth_nlayer)  \n",
    "            \n",
    "        except:\n",
    "            n_truthtracks=0\n",
    "            results_fit[\"tracks_truth\"].append([[-9999]])\n",
    "            results_fit[\"tracks_truth_n\"].append(n_truthtracks)  \n",
    "            results_fit[\"tracks_truth_nlayer\"].append([[-9999]])\n",
    "                  \n",
    "        \n",
    "        # If there is reconstruction:\n",
    "        if len(ev.Tree.Track_k_m_z0)==0:\n",
    "            tracks_recon = [[-9990, -9990, -9990, -9990, -9990, -9990, -9990]]\n",
    "            tracks_recon_n = 0\n",
    "            tracks_recon_error = [[-9990, -9990, -9990, -9990, -9990, -9990, -9990]]\n",
    "            tracks_chi2 = [0]\n",
    "            \n",
    "            tracks_ndigi = [0]\n",
    "            tracks_ndigi_false = [0]\n",
    "            tracks_purity = [-999]\n",
    "            tracks_pdgids = [0]\n",
    "            results_fit[\"mask_recon_success_track\"].append(False)\n",
    "            \n",
    "        else:\n",
    "            tracks_recon = []\n",
    "            tracks_recon_n = Tree.Track_k_m_z0.size()\n",
    "            tracks_recon_error = []\n",
    "            tracks_chi2 = []\n",
    "            tracks_ndigi = []\n",
    "            tracks_ndigi_false = []\n",
    "            tracks_purity = []\n",
    "            tracks_pdgids = []            \n",
    "            \n",
    "            \n",
    "            # Select the reconstruction that is closest to truth\n",
    "            track_digi_hit_inds = util.unzip(Tree.Track_k_m_hitIndices)\n",
    "            track_truth_ids = util.unzip(Tree.Track_k_m_ids)\n",
    "            track_digi_hit_len = np.array([len(i) for i in track_digi_hit_inds])\n",
    "            if tracks_recon_n<n_truthtracks:\n",
    "                results_fit[\"mask_recon_success_track\"].append(False)\n",
    "            else:\n",
    "                results_fit[\"mask_recon_success_track\"].append(True)                \n",
    "                \n",
    "            for i_track in range(len(TruthTracks)):\n",
    "                truth = Truths[i_track]\n",
    "\n",
    "                track_chi2s = []\n",
    "                if len(track_digi_hit_inds)>1:\n",
    "                    for track_ind in range(len(track_digi_hit_inds)):\n",
    "                        recon_i = [Tree.Track_k_m_x0.at(track_ind), Tree.Track_k_m_y0.at(track_ind), Tree.Track_k_m_z0.at(track_ind), Tree.Track_k_m_t0.at(track_ind),Tree.Track_k_m_velX.at(track_ind), Tree.Track_k_m_velY.at(track_ind), Tree.Track_k_m_velZ.at(track_ind)]\n",
    "                        recon_i_unc = [Tree.Track_k_m_ErrorX0.at(track_ind), Tree.Track_k_m_ErrorY0.at(track_ind), Tree.Track_k_m_ErrorZ0.at(track_ind), Tree.Track_k_m_ErrorT0.at(track_ind),Tree.Track_k_m_ErrorVx.at(track_ind), Tree.Track_k_m_ErrorVy.at(track_ind), Tree.Track_k_m_ErrorVz.at(track_ind)]\n",
    "                        chi2 = util.chi2_calc(recon_i,truth,recon_i_unc)\n",
    "                        track_chi2s.append(chi2)\n",
    "                    track_ind = int(np.argmin(track_chi2s))\n",
    "                else:\n",
    "                    track_ind=0\n",
    "\n",
    "                tracks_recon.append([ev.Tree.Track_k_m_x0.at(track_ind), ev.Tree.Track_k_m_y0.at(track_ind), ev.Tree.Track_k_m_z0.at(track_ind), ev.Tree.Track_k_m_t0.at(track_ind), ev.Tree.Track_k_m_velX.at(track_ind), ev.Tree.Track_k_m_velY.at(track_ind), ev.Tree.Track_k_m_velZ.at(track_ind)])\n",
    "                tracks_recon_error.append([ev.Tree.Track_k_m_ErrorX0.at(track_ind), ev.Tree.Track_k_m_ErrorY0.at(track_ind), ev.Tree.Track_k_m_ErrorZ0.at(track_ind), ev.Tree.Track_k_m_ErrorT0.at(track_ind), ev.Tree.Track_k_m_ErrorVx.at(track_ind), ev.Tree.Track_k_m_ErrorVy.at(track_ind), ev.Tree.Track_k_m_ErrorVz.at(track_ind)])\n",
    "                tracks_chi2.append(ev.Tree.Track_k_m_smooth_chi_sum.at(track_ind))\n",
    "                \n",
    "                track_hits_inds=track_digi_hit_inds[track_ind]\n",
    "                truth_pid = TruthTracks[i_track][4][0]\n",
    "                truth_track_id = TruthTracks[i_track][6][0]\n",
    "                kalmantrack_truthtrack_ids = track_truth_ids[track_ind]\n",
    "                \n",
    "                tracks_pdgids.append([ev.Tree.Digi_pdg_id.at(i) for i in track_hits_inds])\n",
    "                tracks_ndigi.append(len(track_hits_inds))\n",
    "                tracks_ndigi_false.append(sum(np.array(kalmantrack_truthtrack_ids)!=truth_track_id))\n",
    "                tracks_purity.append(1-tracks_ndigi_false[-1]/tracks_ndigi[-1])\n",
    "                \n",
    "        # Vertex========================================================\n",
    "        if len(ev.Tree.Vertex_k_m_x)==0:\n",
    "            vertex_recon = [[0]]\n",
    "            vertex_recon_n=0\n",
    "            vertex_recon_error=[[0]]\n",
    "            vertices_chi2=[[0]]\n",
    "            results_fit[\"mask_recon_success_vertex\"].append(False) \n",
    "        else:\n",
    "            results_fit[\"mask_recon_success_vertex\"].append(True) \n",
    "            vertex_recon=[]\n",
    "            vertex_recon_n = Tree.Vertex_k_m_x.size()\n",
    "            vertex_recon_error=[]\n",
    "            vertex_recon_cov=[]\n",
    "            vertices_chi2=[]\n",
    "            for iv in range(vertex_recon_n):\n",
    "                v=[Tree.Vertex_k_m_x.at(iv),Tree.Vertex_k_m_y.at(iv),Tree.Vertex_k_m_z.at(iv),Tree.Vertex_k_m_t.at(iv)]\n",
    "                vertex_recon.append(v)\n",
    "                verr=[Tree.Vertex_k_m_ErrorX.at(iv),Tree.Vertex_k_m_ErrorY.at(iv),Tree.Vertex_k_m_ErrorZ.at(iv),Tree.Vertex_k_m_ErrorT.at(iv)]\n",
    "                vertex_recon_error.append(verr)  \n",
    "                vcov=[[Tree.Vertex_k_m_ErrorX.at(iv)**2, Tree.Vertex_k_m_cov_x_y.at(iv), Tree.Vertex_k_m_cov_x_z.at(iv), Tree.Vertex_k_m_cov_t_x.at(iv)],\n",
    "                      [Tree.Vertex_k_m_cov_x_y.at(iv),   Tree.Vertex_k_m_ErrorY.at(iv)**2, Tree.Vertex_k_m_cov_y_z.at(iv), Tree.Vertex_k_m_cov_t_y.at(iv)],\n",
    "                      [Tree.Vertex_k_m_cov_x_z.at(iv),   Tree.Vertex_k_m_cov_y_z.at(iv), Tree.Vertex_k_m_ErrorZ.at(iv)**2, Tree.Vertex_k_m_cov_t_z.at(iv)],\n",
    "                      [Tree.Vertex_k_m_cov_t_x.at(iv),   Tree.Vertex_k_m_cov_t_y.at(iv), Tree.Vertex_k_m_cov_t_z.at(iv), Tree.Vertex_k_m_ErrorT.at(iv)**2]]\n",
    "                vertex_recon_cov.append(vcov)\n",
    "                vertices_chi2.append(Tree.Vertex_k_m_chi2.at(iv))\n",
    "                \n",
    "        vertex_truth_cms = [Tree.GenParticle_y.at(1)*0.1, -Tree.GenParticle_z.at(1)*0.1 + 8547, Tree.GenParticle_x.at(1)*0.1]\n",
    "        vertex_track_inds = util.unzip(Tree.Vertex_k_m_trackIndices)\n",
    "        vertex_ntrack = [len(ii) for ii in vertex_track_inds]\n",
    "        \n",
    "        \n",
    "        results_fit[\"tracks_recon\"].append(tracks_recon)\n",
    "        results_fit[\"tracks_recon_n\"].append(tracks_recon_n)\n",
    "        results_fit[\"tracks_recon_error\"].append(np.sqrt(tracks_recon_error))\n",
    "        results_fit[\"tracks_chi2\"].append(tracks_chi2)\n",
    "        results_fit[\"tracks_ndigi\"].append(tracks_ndigi)\n",
    "        results_fit[\"tracks_ndigi_false\"].append(tracks_ndigi_false)\n",
    "        results_fit[\"tracks_purity\"].append(tracks_purity)\n",
    "        results_fit[\"tracks_pdgids\"].append(tracks_pdgids)\n",
    "        \n",
    "        results_fit[\"vertices_truth\"].append(vertex_truth_cms)\n",
    "        results_fit[\"vertices_ntrack\"].append(vertex_ntrack)\n",
    "        results_fit[\"vertices_recon\"].append(vertex_recon)\n",
    "        results_fit[\"vertices_recon_n\"].append(vertex_recon_n)\n",
    "        results_fit[\"vertices_recon_error\"].append(vertex_recon_error)\n",
    "        results_fit[\"vertices_recon_cov\"].append(vertex_recon_cov)\n",
    "        results_fit[\"vertices_chi2\"].append(vertices_chi2)\n",
    "        \n",
    "        \n",
    "    for key in [\"tracks_truth_n\",\"tracks_recon_n\",\"mask_recon_success_track\", \"mask_recon_success_vertex\",\"vertices_recon_n\", \"vertices_ntrack_truth\"]:\n",
    "        results_fit[key]=np.array(results_fit[key])\n",
    "        \n",
    "        \n",
    "    return results_fit\n",
    "\n",
    "\n",
    "def closest_approach_midpoint(tr1, tr2):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    ---\n",
    "    tr1,tr2:\n",
    "        lists of track paramters [x0, y0, x0, vx, vy, vz, t0]\n",
    "        \n",
    "    return:\n",
    "    ---\n",
    "    midpoint([x,y,z]), midpoint_time, distance\n",
    "    \"\"\"\n",
    "\n",
    "    rel_v = tr2[3:6] - tr1[3:6];\n",
    "    rel_v2 = np.dot(rel_v, rel_v) \n",
    "\n",
    "    displacement = tr2[:3] - tr1[:3]; # position difference\n",
    "    t_ca = -(  np.dot(displacement, rel_v) - np.dot((tr2[3:6]*tr2[6] - tr1[3:6]*tr1[6]), rel_v)  )/rel_v2;\n",
    "    \n",
    "    displacement = tr1[:3] - tr2[:3]; # position difference\n",
    "    t_ca = (  np.dot(displacement, rel_v) + np.dot((tr2[3:6]*tr2[6] - tr1[3:6]*tr1[6]), rel_v)  )/rel_v2;    \n",
    "    \n",
    "\n",
    "    pos1 = tr1[:3] + tr1[3:6]*(t_ca - tr1[6]);\n",
    "    pos2 = tr2[:3] + tr2[3:6]*(t_ca - tr2[6]);\n",
    "    \n",
    "    line_distance = np.linalg.norm((pos1- pos2))\n",
    "\n",
    "    return (pos1 + pos2)*(0.5), t_ca, line_distance\n",
    "\n",
    "\n",
    "def line_dist(tr1,tr2,t_ca):\n",
    "    pos1 = tr1[:3] + tr1[3:6]*(t_ca - tr1[6]);\n",
    "    pos2 = tr2[:3] + tr2[3:6]*(t_ca - tr2[6]);  \n",
    "    displacement = pos1-pos2\n",
    "    \n",
    "    return np.dot(displacement,displacement)\n",
    "\n",
    "\n",
    "def get_track_cov(Tree, i):\n",
    "    i=int(i)\n",
    "    return np.array([[Tree.Track_k_m_ErrorX0.at(i), 0                           , Tree.Track_k_m_cov_x_z.at(i), Tree.Track_k_m_cov_x_vx.at(i), Tree.Track_k_m_cov_x_vy.at(i), Tree.Track_k_m_cov_x_vz.at(i), Tree.Track_k_m_cov_x_t.at(i)],\n",
    "                    [0                            , Tree.Track_k_m_ErrorY0.at(i), 0                           , 0,0,0,0],\n",
    "                    [Tree.Track_k_m_cov_x_z.at(i), 0                            , Tree.Track_k_m_ErrorZ0.at(i), Tree.Track_k_m_cov_z_vx.at(i), Tree.Track_k_m_cov_z_vy.at(i), Tree.Track_k_m_cov_z_vz.at(i), Tree.Track_k_m_cov_t_z.at(i)],\n",
    "                    [Tree.Track_k_m_cov_x_vx.at(i), 0                            , Tree.Track_k_m_cov_z_vx.at(i), Tree.Track_k_m_ErrorVx.at(i), Tree.Track_k_m_cov_vx_vy.at(i), Tree.Track_k_m_cov_vx_vz.at(i), Tree.Track_k_m_cov_t_vx.at(i)],\n",
    "                    [Tree.Track_k_m_cov_x_vy.at(i), 0                            , Tree.Track_k_m_cov_z_vy.at(i), Tree.Track_k_m_cov_vx_vy.at(i), Tree.Track_k_m_ErrorVy.at(i), Tree.Track_k_m_cov_vy_vz.at(i), Tree.Track_k_m_cov_t_vy.at(i)],\n",
    "                    [Tree.Track_k_m_cov_x_vz.at(i), 0                            , Tree.Track_k_m_cov_z_vz.at(i), Tree.Track_k_m_cov_vx_vz.at(i), Tree.Track_k_m_cov_vy_vz.at(i), Tree.Track_k_m_ErrorVz.at(i), Tree.Track_k_m_cov_t_vz.at(i)],\n",
    "                    [Tree.Track_k_m_cov_x_t.at(i), 0                            , Tree.Track_k_m_cov_t_z.at(i), Tree.Track_k_m_cov_t_vx.at(i), Tree.Track_k_m_cov_t_vy.at(i), Tree.Track_k_m_cov_t_vz.at(i), Tree.Track_k_m_ErrorT0.at(i)],])\n",
    "\n",
    "def get_track_param(Tree,track_ind):\n",
    "    track_ind=int(track_ind)\n",
    "    return np.array([Tree.Track_k_m_x0.at(track_ind), Tree.Track_k_m_y0.at(track_ind), Tree.Track_k_m_z0.at(track_ind),Tree.Track_k_m_velX.at(track_ind), Tree.Track_k_m_velY.at(track_ind), Tree.Track_k_m_velZ.at(track_ind), Tree.Track_k_m_t0.at(track_ind)])\n",
    "\n",
    "\n",
    "def get_track_param_truth_p(Tree,track_ind):\n",
    "    track_ind=int(track_ind)\n",
    "    g4trackind = np.array(util.c2list(Tree.Hit_G4TrackId))\n",
    "    hit_index = int(np.argmax(g4trackind==track_ind))\n",
    "    \n",
    "    return np.array([Tree.Hit_x.at(hit_index), Tree.Hit_y.at(hit_index), Tree.Hit_z.at(hit_index),Tree.Hit_particlePx.at(hit_index), Tree.Hit_particlePy.at(hit_index), Tree.Hit_particlePz.at(hit_index), Tree.Hit_time.at(hit_index)])\n",
    "\n",
    "def get_track_param_truth_v(Tree,track_ind):\n",
    "    track_ind=int(track_ind)\n",
    "    g4trackind = np.array(util.c2list(Tree.Hit_G4TrackId))\n",
    "    hit_index = int(np.argmax(g4trackind==track_ind))\n",
    "    dx = Tree.Hit_x.at(hit_index+1)-Tree.Hit_x.at(hit_index)\n",
    "    dy = Tree.Hit_y.at(hit_index+1)-Tree.Hit_y.at(hit_index)\n",
    "    dz = Tree.Hit_z.at(hit_index+1)-Tree.Hit_z.at(hit_index)\n",
    "    dt = Tree.Hit_time.at(hit_index+1)-Tree.Hit_time.at(hit_index)\n",
    "    \n",
    "    return np.array([Tree.Hit_x.at(hit_index), Tree.Hit_y.at(hit_index), Tree.Hit_z.at(hit_index), dx/dt, dy/dt, dz/dt, Tree.Hit_time.at(hit_index)])\n",
    "\n",
    "\n",
    "def chi2_distance_to(track_param, track_cov, point_xyz,t):\n",
    "    \"\"\"\n",
    "    track_param: (x0,y0,z0, vx,vy,vz, t)\n",
    "    \"\"\"\n",
    "    _x,_y,_z= point_xyz;\n",
    "    x0,y0,z0, vx,vy,vz, t0 = track_param\n",
    "    dy = _y-y0\n",
    "    \n",
    "    # Transform track covariance to covariance of (x,y,z)\n",
    "    jac=np.array([[     1, -vx/vy,    0,         dy/vy,    -vx*dy/(vy*vy),        0,        0],\n",
    "          [ 0, -vz/vy,  1,            0,    -vz*dy/(vy*vy),    dy/vy,        0],\n",
    "            [0,  -1/vy,     0,            0,       -dy/(vy*vy),        0,         1]])\n",
    "    CovMatrix_vertex = jac @ track_cov @ jac.transpose();\n",
    "    \n",
    "    residual_vector = np.array([_x - (x0+vx*dy/vy),     _z- (z0+vz*dy/vy),        t- (t0+dy/vy)])\n",
    "    chi2 = residual_vector.transpose() @np.linalg.inv(CovMatrix_vertex)@residual_vector;\n",
    "    \n",
    "    return chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4bf4b-c651-4a86-8f3d-6fc039530b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_km_alltracks_old(filename, results_fit = None, tree_name=\"integral_tree\", truth_pids = [13,13], nevents=-1):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---\n",
    "    nevents: \n",
    "      -1: all events\n",
    "      (start, stop) from start to stop\n",
    "    \"\"\"\n",
    "    \n",
    "    if results_fit is None:\n",
    "        results_fit={}\n",
    "\n",
    "        \n",
    "    results_fit[\"Entry\"]=[]               # ROOT event entry number\n",
    "    results_fit[\"ndigi\"]=[]               # Total number of digitized hits\n",
    "    results_fit[\"Digi_track_id\"]=[]\n",
    "    results_fit[\"mask_recon_success_track\"]=[]    # Boolean mask \n",
    "    results_fit[\"mask_recon_success_vertex\"]=[]   # Boolean mask \n",
    "    results_fit[\"mask_reconstructible_vertex\"]=[]   # Boolean mask, if an event has two tracks with 4+ hits. The track is required to be from the direct input\n",
    "    results_fit[\"mask_reconstructible2_vertex\"]=[]   # Boolean mask, if an event has two tracks with 4+ hits. The track can be from any particle.  \n",
    "\n",
    "    \n",
    "    results_fit[\"tracks_truth\"]=[]\n",
    "    results_fit[\"tracks_truth_n\"]=[]\n",
    "    results_fit[\"tracks_truth_nlayer\"]=[]\n",
    "    results_fit[\"tracks_truth_pdgids\"]=[]\n",
    "    \n",
    "    results_fit[\"tracks_recon\"]=[]\n",
    "    results_fit[\"tracks_recon_n\"]=[]\n",
    "    results_fit[\"tracks_recon_error\"]=[]          # KF parameter uncertainty. Already taken sqrt()\n",
    "    results_fit[\"tracks_ndigi\"]=[]          #  number of digitized hits in the track\n",
    "    results_fit[\"tracks_ndigi_false\"]=[]    #  number of digitized hits in the track that are not from the truth\n",
    "    results_fit[\"tracks_purity\"]=[]         # List of PDG id of hits in this track \n",
    "    results_fit[\"tracks_pdgids\"]=[]         # List of PDG id of hits in this track \n",
    "    results_fit[\"tracks_chi2\"]=[]           # KF fit chi2\n",
    "    \n",
    "    results_fit[\"vertices_truth\"]=[]\n",
    "    results_fit[\"vertices_ntrack\"]=[]\n",
    "    results_fit[\"vertices_ntrack_truth\"]=[]\n",
    "    results_fit[\"vertices_recon\"]=[]\n",
    "    results_fit[\"vertices_recon_n\"]=[]\n",
    "    results_fit[\"vertices_recon_error\"]=[]\n",
    "    results_fit[\"vertices_recon_cov\"]=[]\n",
    "    results_fit[\"vertices_chi2\"]=[]\n",
    "    \n",
    "\n",
    "\n",
    "    ev = event.Event(filename, 0, tree_name=tree_name)\n",
    "    Tree=ev.Tree\n",
    "    nevents_total = int(ev.Tree.GetEntries())\n",
    "    cut=cutflow.sample_space(\"\")\n",
    "    \n",
    "    if nevents==-1:\n",
    "        nevents = [0, nevents_total]\n",
    "    elif type(nevents) is int:\n",
    "        if nevents_total<nevents:\n",
    "            print(f\"Requested events exceed total {nevents_total}\")\n",
    "        nevents = [0, min(nevents,nevents_total)]\n",
    "    else:\n",
    "        if nevents_total<nevents[1]:\n",
    "            print(f\"Requested events exceed total {nevents_total}\")        \n",
    "        nevents = [nevents[0], min(nevents[1],nevents_total)]\n",
    "\n",
    "    for i_event in tqdm(range(nevents[0], nevents[1])):\n",
    "        ev.EventNumber=i_event\n",
    "        ev.Tree.GetEntry(i_event)\n",
    "        ev.ExtractTruthPhysics_list()\n",
    "        \n",
    "        par_km_ndigi = ev.Tree.Digi_x.size()\n",
    "        \n",
    "        results_fit[\"Entry\"].append(i_event)\n",
    "        results_fit[\"ndigi\"].append(par_km_ndigi)\n",
    "        results_fit[\"Digi_track_id\"].append(util.c2list(ev.Tree.Digi_track_id))\n",
    "        ids=np.array(results_fit[\"Digi_track_id\"][-1])\n",
    "        ys = np.array(util.c2list(ev.Tree.Digi_y))\n",
    "        n_reconstructible=0\n",
    "        n_reconstructible2=0\n",
    "        for g4id in range(0,200):\n",
    "            if len(np.unique(ys[ids==g4id]))>=4:\n",
    "                n_reconstructible+=1\n",
    "        for g4id in np.unique(ids):\n",
    "            if len(np.unique(ys[ids==g4id]))>=4:\n",
    "                n_reconstructible2+=1                \n",
    "        results_fit[\"vertices_ntrack_truth\"].append(n_reconstructible)\n",
    "        if n_reconstructible>=2:\n",
    "            results_fit[\"mask_reconstructible_vertex\"].append(True)\n",
    "        else:\n",
    "            results_fit[\"mask_reconstructible_vertex\"].append(False)   \n",
    "        if n_reconstructible2>=2:\n",
    "            results_fit[\"mask_reconstructible2_vertex\"].append(True)\n",
    "        else:\n",
    "            results_fit[\"mask_reconstructible2_vertex\"].append(False)               \n",
    "\n",
    "        # Get truth (speed need to be calculated by hand)\n",
    "        try:\n",
    "            # Truth position and speed\n",
    "            TruthTracks = []\n",
    "            Truths = []\n",
    "            Truth_nlayer = []\n",
    "            Truth_pdgids = []\n",
    "            for track in ev.truthTrackList_list:\n",
    "                if track[4][0] in truth_pids:\n",
    "                    TruthTracks.append(track)\n",
    "                    dt=track[3][1]-track[3][0]\n",
    "                    vx=(track[0][1]-track[0][0])/dt\n",
    "                    vy=(track[1][1]-track[1][0])/dt\n",
    "                    vz=(track[2][1]-track[2][0])/dt\n",
    "                    truth = [track[0][0], track[1][0], track[2][0], track[3][0],vx,vy,vz]  \n",
    "                    Truths.append(truth)\n",
    "                    Truth_nlayer.append(np.abs(cut.in_layer(track[1][-1])-cut.in_layer(track[1][0])))\n",
    "                    Truth_pdgids.append(track[4][0])\n",
    "            \n",
    "            n_truthtracks=len(TruthTracks)\n",
    "            results_fit[\"tracks_truth\"].append(Truths)  \n",
    "            results_fit[\"tracks_truth_n\"].append(n_truthtracks)  \n",
    "            results_fit[\"tracks_truth_nlayer\"].append(Truth_nlayer)  \n",
    "            \n",
    "        except:\n",
    "            n_truthtracks=0\n",
    "            results_fit[\"tracks_truth\"].append([[-9999]])\n",
    "            results_fit[\"tracks_truth_n\"].append(n_truthtracks)  \n",
    "            results_fit[\"tracks_truth_nlayer\"].append([[-9999]])\n",
    "                  \n",
    "        \n",
    "        # If there is reconstruction:\n",
    "        if len(ev.Tree.Track_k_m_z0)==0:\n",
    "            tracks_recon = [[-9990, -9990, -9990, -9990, -9990, -9990, -9990]]\n",
    "            tracks_recon_n = 0\n",
    "            tracks_recon_error = [[-9990, -9990, -9990, -9990, -9990, -9990, -9990]]\n",
    "            tracks_chi2 = [0]\n",
    "            \n",
    "            tracks_ndigi = [0]\n",
    "            tracks_ndigi_false = [0]\n",
    "            tracks_purity = [-999]\n",
    "            tracks_pdgids = [0]\n",
    "            results_fit[\"mask_recon_success_track\"].append(False)\n",
    "            \n",
    "        else:\n",
    "            tracks_recon = []\n",
    "            tracks_recon_n = Tree.Track_k_m_z0.size()\n",
    "            tracks_recon_error = []\n",
    "            tracks_chi2 = []\n",
    "            tracks_ndigi = []\n",
    "            tracks_ndigi_false = []\n",
    "            tracks_purity = []\n",
    "            tracks_pdgids = []            \n",
    "            \n",
    "            \n",
    "            # Select the reconstruction that is closest to truth\n",
    "            track_digi_hit_inds = util.unzip(Tree.Track_k_m_hitIndices)\n",
    "            track_truth_ids = util.unzip(Tree.Track_k_m_ids)\n",
    "            track_digi_hit_len = np.array([len(i) for i in track_digi_hit_inds])\n",
    "            if tracks_recon_n<n_truthtracks:\n",
    "                results_fit[\"mask_recon_success_track\"].append(False)\n",
    "            else:\n",
    "                results_fit[\"mask_recon_success_track\"].append(True)                \n",
    "                \n",
    "            for i_track in range(len(TruthTracks)):\n",
    "                truth = Truths[i_track]\n",
    "\n",
    "                track_chi2s = []\n",
    "                if len(track_digi_hit_inds)>1:\n",
    "                    for track_ind in range(len(track_digi_hit_inds)):\n",
    "                        recon_i = [Tree.Track_k_m_x0.at(track_ind), Tree.Track_k_m_y0.at(track_ind), Tree.Track_k_m_z0.at(track_ind), Tree.Track_k_m_t0.at(track_ind),Tree.Track_k_m_velX.at(track_ind), Tree.Track_k_m_velY.at(track_ind), Tree.Track_k_m_velZ.at(track_ind)]\n",
    "                        recon_i_unc = [Tree.Track_k_m_ErrorX0.at(track_ind), Tree.Track_k_m_ErrorY0.at(track_ind), Tree.Track_k_m_ErrorZ0.at(track_ind), Tree.Track_k_m_ErrorT0.at(track_ind),Tree.Track_k_m_ErrorVx.at(track_ind), Tree.Track_k_m_ErrorVy.at(track_ind), Tree.Track_k_m_ErrorVz.at(track_ind)]\n",
    "                        chi2 = util.chi2_calc(recon_i,truth,recon_i_unc)\n",
    "                        track_chi2s.append(chi2)\n",
    "                    track_ind = int(np.argmin(track_chi2s))\n",
    "                else:\n",
    "                    track_ind=0\n",
    "\n",
    "                tracks_recon.append([ev.Tree.Track_k_m_x0.at(track_ind), ev.Tree.Track_k_m_y0.at(track_ind), ev.Tree.Track_k_m_z0.at(track_ind), ev.Tree.Track_k_m_t0.at(track_ind), ev.Tree.Track_k_m_velX.at(track_ind), ev.Tree.Track_k_m_velY.at(track_ind), ev.Tree.Track_k_m_velZ.at(track_ind)])\n",
    "                tracks_recon_error.append([ev.Tree.Track_k_m_ErrorX0.at(track_ind), ev.Tree.Track_k_m_ErrorY0.at(track_ind), ev.Tree.Track_k_m_ErrorZ0.at(track_ind), ev.Tree.Track_k_m_ErrorT0.at(track_ind), ev.Tree.Track_k_m_ErrorVx.at(track_ind), ev.Tree.Track_k_m_ErrorVy.at(track_ind), ev.Tree.Track_k_m_ErrorVz.at(track_ind)])\n",
    "                tracks_chi2.append(ev.Tree.Track_k_m_smooth_chi_sum.at(track_ind))\n",
    "                \n",
    "                track_hits_inds=track_digi_hit_inds[track_ind]\n",
    "                truth_pid = TruthTracks[i_track][4][0]\n",
    "                truth_track_id = TruthTracks[i_track][6][0]\n",
    "                kalmantrack_truthtrack_ids = track_truth_ids[track_ind]\n",
    "                \n",
    "                tracks_pdgids.append([ev.Tree.Digi_pdg_id.at(i) for i in track_hits_inds])\n",
    "                tracks_ndigi.append(len(track_hits_inds))\n",
    "                tracks_ndigi_false.append(sum(np.array(kalmantrack_truthtrack_ids)!=truth_track_id))\n",
    "                tracks_purity.append(1-tracks_ndigi_false[-1]/tracks_ndigi[-1])\n",
    "                \n",
    "        # Vertex========================================================\n",
    "        if len(ev.Tree.Vertex_k_m_x)==0:\n",
    "            vertex_recon = [[0]]\n",
    "            vertex_recon_n=0\n",
    "            vertex_recon_error=[[0]]\n",
    "            vertices_chi2=[[0]]\n",
    "            results_fit[\"mask_recon_success_vertex\"].append(False) \n",
    "        else:\n",
    "            results_fit[\"mask_recon_success_vertex\"].append(True) \n",
    "            vertex_recon=[]\n",
    "            vertex_recon_n = Tree.Vertex_k_m_x.size()\n",
    "            vertex_recon_error=[]\n",
    "            vertex_recon_cov=[]\n",
    "            vertices_chi2=[]\n",
    "            for iv in range(vertex_recon_n):\n",
    "                v=[Tree.Vertex_k_m_x.at(iv),Tree.Vertex_k_m_y.at(iv),Tree.Vertex_k_m_z.at(iv),Tree.Vertex_k_m_t.at(iv)]\n",
    "                vertex_recon.append(v)\n",
    "                verr=[Tree.Vertex_k_m_ErrorX.at(iv),Tree.Vertex_k_m_ErrorY.at(iv),Tree.Vertex_k_m_ErrorZ.at(iv),Tree.Vertex_k_m_ErrorT.at(iv)]\n",
    "                vertex_recon_error.append(verr)  \n",
    "                vcov=[[Tree.Vertex_k_m_ErrorX.at(iv)**2, Tree.Vertex_k_m_cov_x_y.at(iv), Tree.Vertex_k_m_cov_x_z.at(iv), Tree.Vertex_k_m_cov_t_x.at(iv)],\n",
    "                      [Tree.Vertex_k_m_cov_x_y.at(iv),   Tree.Vertex_k_m_ErrorY.at(iv)**2, Tree.Vertex_k_m_cov_y_z.at(iv), Tree.Vertex_k_m_cov_t_y.at(iv)],\n",
    "                      [Tree.Vertex_k_m_cov_x_z.at(iv),   Tree.Vertex_k_m_cov_y_z.at(iv), Tree.Vertex_k_m_ErrorZ.at(iv)**2, Tree.Vertex_k_m_cov_t_z.at(iv)],\n",
    "                      [Tree.Vertex_k_m_cov_t_x.at(iv),   Tree.Vertex_k_m_cov_t_y.at(iv), Tree.Vertex_k_m_cov_t_z.at(iv), Tree.Vertex_k_m_ErrorT.at(iv)**2]]\n",
    "                vertex_recon_cov.append(vcov)\n",
    "                vertices_chi2.append(Tree.vertex_k_m_chi2.at(iv))\n",
    "                \n",
    "        vertex_truth_cms = [Tree.GenParticle_y.at(1)*0.1, -Tree.GenParticle_z.at(1)*0.1 + 8547, Tree.GenParticle_x.at(1)*0.1]\n",
    "        vertex_track_inds = util.unzip(Tree.Vertex_k_m_trackIndices)\n",
    "        vertex_ntrack = [len(ii) for ii in vertex_track_inds]\n",
    "        \n",
    "        \n",
    "        results_fit[\"tracks_recon\"].append(tracks_recon)\n",
    "        results_fit[\"tracks_recon_n\"].append(tracks_recon_n)\n",
    "        results_fit[\"tracks_recon_error\"].append(np.sqrt(tracks_recon_error))\n",
    "        results_fit[\"tracks_chi2\"].append(tracks_chi2)\n",
    "        results_fit[\"tracks_ndigi\"].append(tracks_ndigi)\n",
    "        results_fit[\"tracks_ndigi_false\"].append(tracks_ndigi_false)\n",
    "        results_fit[\"tracks_purity\"].append(tracks_purity)\n",
    "        results_fit[\"tracks_pdgids\"].append(tracks_pdgids)\n",
    "        \n",
    "        results_fit[\"vertices_truth\"].append(vertex_truth_cms)\n",
    "        results_fit[\"vertices_ntrack\"].append(vertex_ntrack)\n",
    "        results_fit[\"vertices_recon\"].append(vertex_recon)\n",
    "        results_fit[\"vertices_recon_n\"].append(vertex_recon_n)\n",
    "        results_fit[\"vertices_recon_error\"].append(vertex_recon_error)\n",
    "        results_fit[\"vertices_recon_cov\"].append(vertex_recon_cov)\n",
    "        results_fit[\"vertices_chi2\"].append(vertices_chi2)\n",
    "        \n",
    "        \n",
    "    for key in [\"tracks_truth_n\",\"tracks_recon_n\",\"mask_recon_success_track\", \"mask_recon_success_vertex\",\"vertices_recon_n\", \"vertices_ntrack_truth\"]:\n",
    "        results_fit[key]=np.array(results_fit[key])\n",
    "        \n",
    "        \n",
    "    return results_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec25678-b2d8-4976-b0e3-0c1dd8897715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_vertex(filename):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    [[x, y, z, px, py, pz],[x, y, z, px, py, pz],...]\n",
    "    \"\"\"\n",
    "    vertices = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if \"#\" in line:\n",
    "                continue\n",
    "            else:\n",
    "                line = line.split()\n",
    "                if len(line)>0 and line[0] == \"n\":\n",
    "                    while True:\n",
    "                        line2 = f.readline()\n",
    "                        if \"#\" in line2:\n",
    "                            continue                           \n",
    "                        line2 = line2.split()\n",
    "                        if len(line2)>0:\n",
    "                            break\n",
    "                    vertex = [float(line2[1]), float(line2[2]), float(line2[3]), float(line[6]), float(line[7]), float(line[8])] # x, y, z, px, py, pz\n",
    "                    vertices.append(vertex)\n",
    "                else:\n",
    "                    continue\n",
    "    return np.array(vertices)\n",
    "\n",
    "\n",
    "def read_raw_vertex_weight(filename):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    [[x, y, z, px, py, pz],[x, y, z, px, py, pz],...]\n",
    "    \"\"\"\n",
    "    vertices = []\n",
    "    weights = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if \"#\" in line:\n",
    "                if \"### weight\" in line:\n",
    "                    line = line.split()\n",
    "                    weights.append([float(line[2]), float(line[3]), float(line[4])])\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                line = line.split()\n",
    "                if len(line)>0 and line[0] == \"n\":\n",
    "                    while True:\n",
    "                        line2 = f.readline()\n",
    "                        if \"#\" in line2:\n",
    "                            continue                           \n",
    "                        line2 = line2.split()\n",
    "                        if len(line2)>0:\n",
    "                            break\n",
    "                    vertex = [float(line2[1]), float(line2[2]), float(line2[3]), float(line[6]), float(line[7]), float(line[8])] # x, y, z, px, py, pz\n",
    "                    vertices.append(vertex)\n",
    "                else:\n",
    "                    continue\n",
    "    return np.array(vertices), np.array(weights)\n",
    "\n",
    "\n",
    "def read_raw_vertex_ntracks(filename):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    list of number of tracks in each vertex\n",
    "    \"\"\"\n",
    "    ntracks = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if \"#\" in line:\n",
    "                continue\n",
    "            else:\n",
    "                line = line.split()\n",
    "                if len(line)>0:\n",
    "                    if line[0] == \"n\":\n",
    "                        ntracks.append(0)                \n",
    "                    else:\n",
    "                        ntracks[-1]+=1\n",
    "    return np.array(ntracks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
